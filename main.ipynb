{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831554a1",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "This notebook is structured to address the following objectives:\n",
    "1. **Preprocessing and Classification**: Perform appropriate preprocessing and classification on the given dataset.\n",
    "2. **Handling Imbalanced Data**: Identify if the data is imbalanced and apply measures like SMOTE and feature extraction.\n",
    "3. **Imputation**: Perform imputation using Scikit-learn's available imputers.\n",
    "4. **Bagging and Boosting**: Apply bagging and boosting techniques.\n",
    "5. **LDA and QDA**: Perform Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA).\n",
    "6. **Advanced Techniques**: Use techniques like Pipelines, Column Transformers, and hyperparameter tuning, referencing Scikit-learn documentation.\n",
    "7. **Scaling and Imputing Comparison**: Compare different approaches to scaling and imputing and analyze their effects on model performance.\n",
    "8. **Model Evaluation**: Evaluate the model using multiple metrics and justify the most appropriate ones for the given scenario.\n",
    "\n",
    "## Step 1: Data Handling and Preprocessing\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "data = pd.read_csv(\"dataset_task1.csv\")\n",
    "print(data.head())\n",
    "data.info()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a93faf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform appropriate preprocessing and classification on the given dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: Preprocessing, Models, Metrics, and Pipelines\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Scikit-learn: Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "# Imbalanced-learn: Handling Class Imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline # Renaming to avoid conflict with sklearn.pipeline\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"dataset_task1.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "736a717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# here 'TotalCharges' is assumed to be the target variable\n",
    "features = data.drop(columns=['TotalCharges'])\n",
    "target = data['TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a41db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify if the data is imbalanced and apply appropriate measures to handle it like SMOTE and feature extraction\n",
    "# Display dataset information\n",
    "data.info()\n",
    "\n",
    "# Define features and target BEFORE encoding\n",
    "features = data.drop(columns=['PhoneService'])\n",
    "target = data['PhoneService']\n",
    "\n",
    "# Convert non-numeric columns to numeric using encoding\n",
    "for column in features.select_dtypes(include=['object']).columns:\n",
    "    features[column] = features[column].astype('category').cat.codes\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, \n",
    "    test_size=0.2, \n",
    "    random_state=404, \n",
    "    stratify=target\n",
    "    )\n",
    "\n",
    "# Visualize class distribution\n",
    "sns.countplot(x=y_train)\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.show()\n",
    "\n",
    "# Apply SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b4fac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets which will be used later for model training and evaluation\n",
    "# Using stratify to handle class imbalance if present\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, \n",
    "    test_size=0.2, \n",
    "    random_state=404, \n",
    "    stratify=target\n",
    "    #it helps to maintains the same proportion of classes as the original dataset and not overpowering the minority class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b812e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Imputation based on Imputers available on Scikit Learn\n",
    "imputer = SimpleImputer(strategy='mean', add_indicator=True)\n",
    "X_train_imputed = imputer.fit_transform(X_train_smote)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8277a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using StandardScaler and MinMaxScaler\n",
    "# Standardization\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train_imputed)\n",
    "X_test_standard = scaler_standard.transform(X_test_imputed)\n",
    "\n",
    "# Normalization\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train_minmax = scaler_minmax.fit_transform(X_train_imputed)\n",
    "X_test_minmax = scaler_minmax.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6429353",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Ordinal Encoding pipeline (impute then encode)\u001b[39;00m\n\u001b[32m      5\u001b[39m ordinal_pipeline = Pipeline(steps=[\n\u001b[32m      6\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m, SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmost_frequent\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m      7\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mencoder\u001b[39m\u001b[33m'\u001b[39m, OrdinalEncoder(handle_unknown=\u001b[33m'\u001b[39m\u001b[33muse_encoded_value\u001b[39m\u001b[33m'\u001b[39m, unknown_value=-\u001b[32m1\u001b[39m))\n\u001b[32m      8\u001b[39m ])\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_train_ordinal = \u001b[43mordinal_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m X_test_ordinal = ordinal_pipeline.transform(X_test[categorical_cols])\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# One-Hot Encoding pipeline (impute then one-hot)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\pipeline.py:719\u001b[39m, in \u001b[36mPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[32m    681\u001b[39m \n\u001b[32m    682\u001b[39m \u001b[33;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    716\u001b[39m \u001b[33;03m    Transformed samples.\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    718\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m last_step = \u001b[38;5;28mself\u001b[39m._final_estimator\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\impute\\_base.py:452\u001b[39m, in \u001b[36mSimpleImputer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    436\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m    438\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\impute\\_base.py:379\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    377\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m in_fit:\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_dtype = X.dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\impute\\_base.py:360\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    357\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:929\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    925\u001b[39m pandas_requires_conversion = \u001b[38;5;28many\u001b[39m(\n\u001b[32m    926\u001b[39m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[32m    927\u001b[39m )\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np.dtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     dtype_orig = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[32m    931\u001b[39m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[32m    932\u001b[39m     dtype_orig = \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "# Encoding categorical features using OrdinalEncoder and OneHotEncoder on categorical columns only\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Ordinal Encoding pipeline (impute then encode)\n",
    "ordinal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "X_train_ordinal = ordinal_pipeline.fit_transform(X_train[categorical_cols])\n",
    "X_test_ordinal = ordinal_pipeline.transform(X_test[categorical_cols])\n",
    "\n",
    "# One-Hot Encoding pipeline (impute then one-hot)\n",
    "onehot_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "X_train_onehot = onehot_pipeline.fit_transform(X_train[categorical_cols])\n",
    "X_test_onehot = onehot_pipeline.transform(X_test[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling class imbalance\n",
    "# Step 1: Identify class imbalance using EDA\n",
    "# Visualize class distribution\n",
    "sns.countplot(x=y_train)\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.show()\n",
    "\n",
    "# Display value counts\n",
    "print(\"Class distribution in training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Step 2: Apply oversampling techniques\n",
    "# Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train_imputed, y_train)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_imputed, y_train)\n",
    "\n",
    "# Step 3: Apply undersampling techniques\n",
    "# Random Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_imputed, y_train)\n",
    "\n",
    "# Edited Nearest Neighbours\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours()\n",
    "X_train_enn, y_train_enn = enn.fit_resample(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bagging and boosting techniques\n",
    "# Bagging using Random Forest\n",
    "bagging_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "bagging_model.fit(X_train_imputed, y_train_smote)\n",
    "print(\"Bagging (Random Forest) Training Accuracy:\", bagging_model.score(X_train_imputed, y_train_smote))\n",
    "print(\"Bagging (Random Forest) Testing Accuracy:\", bagging_model.score(X_test_imputed, y_test))\n",
    "\n",
    "# Boosting using Gradient Boosting\n",
    "boosting_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "boosting_model.fit(X_train_imputed, y_train_smote)\n",
    "print(\"Boosting (Gradient Boosting) Training Accuracy:\", boosting_model.score(X_train_imputed, y_train_smote))\n",
    "print(\"Boosting (Gradient Boosting) Testing Accuracy:\", boosting_model.score(X_test_imputed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46769be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Selection: Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Logistic Regression Training Accuracy:\", logistic_model.score(X_train_smote, y_train_smote))\n",
    "print(\"Logistic Regression Testing Accuracy:\", logistic_model.score(X_test_imputed, y_test))\n",
    "# Model Training and Selection: Random Forest\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Random Forest Training Accuracy:\", random_forest_model.score(X_train_smote, y_train_smote))\n",
    "print(\"Random Forest Testing Accuracy:\", random_forest_model.score(X_test_imputed, y_test))\n",
    "# Model Training and Selection: Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Gradient Boosting Training Accuracy:\", gb_model.score(X_train_smote, y_train_smote))\n",
    "print(\"Gradient Boosting Testing Accuracy:\", gb_model.score(X_test_imputed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa82946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LDA and QDA on the dataset\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train_imputed, y_train_smote)\n",
    "print(\"LDA Training Accuracy:\", lda_model.score(X_train_imputed, y_train_smote))\n",
    "print(\"LDA Testing Accuracy:\", lda_model.score(X_test_imputed, y_test))\n",
    "\n",
    "# Quadratic Discriminant Analysis (QDA)\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train_imputed, y_train_smote)\n",
    "print(\"QDA Training Accuracy:\", qda_model.score(X_train_imputed, y_train_smote))\n",
    "print(\"QDA Testing Accuracy:\", qda_model.score(X_test_imputed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b41673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavily reference the scikit-learn documentation as well as reference videos and use techniques like Pipelines, Column Transformers and hyperparameter tuning\n",
    "# Define preprocessing for numeric and categorical features based on original dtypes\n",
    "X_full = data.drop(columns=[target.name])\n",
    "numeric_cols = X_full.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols_for_ct = X_full.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols_for_ct)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff546d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different approaches to scaling and imputing and analyze how they affect the model performance\n",
    "scaling_methods = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler()\n",
    "}\n",
    "\n",
    "imputing_methods = {\n",
    "    'MeanImputation': SimpleImputer(strategy='mean'),\n",
    "    'MostFrequentImputation': SimpleImputer(strategy='most_frequent')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for scaler_name, scaler in scaling_methods.items():\n",
    "    for imputer_name, imputer in imputing_methods.items():\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', imputer),\n",
    "            ('scaler', scaler)\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, features.select_dtypes(include=['int64', 'float64']).columns),\n",
    "                ('cat', categorical_transformer, features.select_dtypes(include=['object']).columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        results.append({\n",
    "            'Scaler': scaler_name,\n",
    "            'Imputer': imputer_name,\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'Precision': report['weighted avg']['precision'],\n",
    "            'Recall': report['weighted avg']['recall'],\n",
    "            'F1-Score': report['weighted avg']['f1-score']\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0031f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using multiple metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Robust ROC AUC for binary or multiclass\n",
    "y_proba = None\n",
    "try:\n",
    "    y_proba = best_model.predict_proba(X_test)\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        roc_auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "except Exception:\n",
    "    roc_auc = np.nan\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Justification for metrics\n",
    "print(\"\\nJustification:\")\n",
    "print(\"Accuracy is a general metric but may not be sufficient in case of class imbalance.\")\n",
    "print(\"Precision and Recall are critical for imbalanced datasets, as they measure the ability to correctly identify positive cases and avoid false negatives.\")\n",
    "print(\"F1-Score provides a balance between Precision and Recall, making it suitable for imbalanced scenarios.\")\n",
    "print(\"ROC AUC is useful for evaluating the model's ability to distinguish between classes, especially in multi-class problems.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
